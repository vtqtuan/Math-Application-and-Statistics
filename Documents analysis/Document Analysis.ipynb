{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"colab":{"name":"18127248.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"3-HaFy4MEjSG","colab_type":"text"},"source":["# PROJECT O4: DOCUMENTS CLASSIFICATION WITH LINEAR REGRESSION\n","----\n","##### Giảng viên hướng dẫn: ***Trần Thị Thảo Nhi***.\n","##### Sinh viên thực hiện: ***Võ Trần Quang Tuấn*** - ID: ***18127248***\n","##### Môn học: Toán ứng dụng và thống kê - MTH00051(18CLC2).\n","##### Trường đại học Khoa học Tự Nhiên - ĐHQG TPHCM.\n","##### Khoa Công nghệ Thông tin - FIT HCMUS.\n","----"]},{"cell_type":"markdown","metadata":{"id":"9gkS2O_VV504","colab_type":"text"},"source":["## PROPLEM DESCRIPTIONS\n","> Xử lý dữ liệu dạng văn bản.  \n","Sử dụng mô hình hồi quy tuyến tính dùng bình phương tối tiểu.  \n","Sử dụng độ chính xác để đánh giá mô hình.\n"]},{"cell_type":"markdown","metadata":{"id":"Q4yWjBDqXThn","colab_type":"text"},"source":["## CODE - REPORT DESCRIPTIONS\n","> Report đi kèm với file .ipynb, được viết dạng markdown.  \n","Code python được viết trên từng cell, theo từng quá trình xử lý và chức năng nhất định.  \n","Để run, chạy cell by cell và kiểm tra kết quả.\n"]},{"cell_type":"markdown","metadata":{"id":"I2RnLGwhYyEL","colab_type":"text"},"source":["## HIỆN THỰC HOÁ QUÁ TRÌNH"]},{"cell_type":"markdown","metadata":{"id":"d7EAGAivGMTH","colab_type":"text"},"source":["###I. Import các thư viện cần thiết cho việc phân tích văn bản."]},{"cell_type":"code","metadata":{"id":"HQbtr_jfqdD8","colab_type":"code","colab":{}},"source":["# DON'T CHANGE this part: import libraries\n","import numpy as np\n","import scipy\n","import json\n","from nltk.stem import PorterStemmer \n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize \n","import re\n","import itertools"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Aid1Q8Z7G6-P","colab_type":"text"},"source":["### II. Phần nhập tên file train và file validation test:"]},{"cell_type":"code","metadata":{"id":"TYigj_FbqdEB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1599663528331,"user_tz":-420,"elapsed":27334,"user":{"displayName":"Quang Tuấn Võ Trần","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTSWSVAF1KiDNCU5eVGF0F26JXJ1HjprJg9JdK=s64","userId":"11002199741059132758"}},"outputId":"61ab61c0-2fb8-4eb9-f9ad-7c2044b10220"},"source":["# DON'T CHANGE this part: read data path\n","train_set_path, valid_set_path, random_number = input().split()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["train.json valid.json 10\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FtCT3VoOYhiU","colab_type":"text"},"source":["### III. Preprocessing.\n","> Converting text to lower case.  \n","Converting number to `num`.  \n","Tokenization.    \n","Removing stopword.  \n","Stemming."]},{"cell_type":"markdown","metadata":{"id":"M9zqpdmsFYol","colab_type":"text"},"source":["#### 1. Đọc file dữ liệu dạng json, tách thành hai trường: overall và review.\n","- overall: danh sách các đánh giá của người dùng (từ 1 -> 5), dạng `float`.\n","- review: danh sách các review của người dùng, có dạng là `string`"]},{"cell_type":"code","metadata":{"id":"0oGwAW502H-1","colab_type":"code","colab":{}},"source":["def read_data(file_path):\n","  data_file = open(file_path, 'r')\n","  data = json.loads(data_file.read())\n","  overall = [item['overall'] for item in data]\n","  review = [item['reviewText'] for item in data]\n","  return overall, review"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C9X3HZAjGoDx","colab_type":"text"},"source":["#### 2. Chuyển hoá nhãn thành vector.\n","- Vì mỗi label đều ở dạng một con số `float`, cho nên ta phải chuyển về một vector 5 chiều tương ứng với 5 loại đánh giá từ 1->5.\n","- Mỗi vector có 5 phần tử, đánh giá thuộc loại nào thì phần tử có chỉ số point-1 sẽ có giá trị là 1, các phần tử còn lại bằng 0, với point là overall.\n","- Trả về ma trận label có chiều `Nx5` với N là số người tham gia đánh giá.  \n","- ***ĐÂY CHÍNH LÀ KĨ THUẬT ONE-HOT ENCODING***"]},{"cell_type":"code","metadata":{"id":"bH1E-nujGSOo","colab_type":"code","colab":{}},"source":["def convert_label(lst_overall):\n","  N = len(lst_overall)\n","  label_matrix = np.zeros((N, 5))\n","  for index in range(N):\n","    label = int(lst_overall[index])\n","    label_matrix[index, label-1] = 1\n","  return label_matrix"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-je_oim3LQNu","colab_type":"text"},"source":["#### 3. Xử lý text dạng `string`.\n","- Chuyển toàn bộ text thành chữ thường.\n","- Tách token.\n","- Xoá stopwords trong tiếng anh.\n","- Chuyển các từ dẫn xuất thành nguyên mẫu từ (stemming).\n","- Chuyển số thành `num`."]},{"cell_type":"code","metadata":{"id":"tbdmxuX-MD0g","colab_type":"code","colab":{}},"source":["def preprocessing(text):\n","  # lower sentence\n","  text = text.lower()\n","  # tokenize\n","  words = word_tokenize(text)\n","  # remove stopwords\n","  en_stops = set(stopwords.words('english'))\n","  words_new = []\n","  for i in range(len(words)):\n","    if words[i] not in en_stops:\n","      words_new.append(words[i])\n","  # stemming\n","  st = PorterStemmer()\n","  for i in range(len(words_new)):\n","    if words_new[i].isnumeric():\n","      words_new[i] = 'num'\n","    else:\n","      words_new[i] = st.stem(words_new[i])\n","  return words_new"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zgS1zEXYxMp9","colab_type":"text"},"source":["#### 4. Xử lý text trong tập valid.json.\n","- Những từ nào chưa có trong tập vocab thì chuyển thành `unk`\n","- Tiền xử lý như các đoạn text trong tập train.\n","- vocab thuộc kiểu `set`, chứa các từ của tập train trong corpus."]},{"cell_type":"code","metadata":{"id":"3Z1Ew7eDzAIS","colab_type":"code","colab":{}},"source":["def valid_text_processing(text, vocab):\n","  tokens = preprocessing(text)\n","  for i in range(len(tokens)):\n","    if tokens[i] not in vocab:\n","      tokens[i] = 'unk'\n","  return tokens"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jNME7Ipl1r5x","colab_type":"text"},"source":["#### 5. Tạo tập vocab.\n","- Sử dụng text trong tập train để tạo tập vocab.\n","- Vocab sẽ thuộc kiểu `set`, mục đích để truy xuất đến các phần tử nhanh hơn."]},{"cell_type":"code","metadata":{"id":"aSEQKhFn1rJC","colab_type":"code","colab":{}},"source":["def make_vocab(training_set):\n","  vocab = set()\n","  for text in training_set:\n","    tokens = preprocessing(text)\n","    for token in tokens:\n","      vocab.add(token)\n","  return vocab"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"66R42llb4lzO","colab_type":"text"},"source":["#### 6. Tạo histogram vector cho từng đoạn text review, và tạo histogram matrix.\n","- `make_histogram_vector(text, vocab)`: tạo vector histogram cho từng đoạn text\n","- `embedding(dataset, vocab)`: xây dựng ma trận histogram với tập vocab và dataset."]},{"cell_type":"code","metadata":{"id":"2cyBTWeH9N7G","colab_type":"code","colab":{}},"source":["def make_histogram_vector(text, vocab):\n","  tokens = valid_text_processing(text, vocab)\n","  vocab_size = len(vocab)\n","  fre = np.zeros(vocab_size)\n","  i = 0\n","  for word in vocab:\n","    fre[i] = tokens.count(word)\n","    i += 1\n","  return fre/np.sum(fre)\n","\n","def embedding(dataset, vocab):\n","  histogram_matrix = []\n","  for text in dataset:\n","    fre = make_histogram_vector(text, vocab)\n","    histogram_matrix.append(fre)\n","  return np.array(histogram_matrix)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7asjn4lBIdV4","colab_type":"text"},"source":["### IV. Quá trình huấn luyện model.\n","> Cài đặt hàm hồi quy tuyến tính.  \n","Tìm tham số hồi quy."]},{"cell_type":"markdown","metadata":{"id":"O0sKayp9Aq_C","colab_type":"text"},"source":["#### 1. Cài đặt hàm tính tham số của model hồi quy tuyến tính.\n","- Ma trận input đầu vào sẽ có dạng `Nxn`, với N là số đoạn text trong dataset, n là số phần tử tập vocab.\n","- Tham số theta cần huấn luyện có dạng `nx5`, n là số phần tử tập vocab, model này sẽ trả về một vector 5 chiều tương ứng với 5 loại đánh giá.\n","- Ma trận nhãn (label) có dạng `Nx5` với N là số đoạn text trong dataset.\n"]},{"cell_type":"code","metadata":{"id":"tsoXJuHIAo07","colab_type":"code","colab":{}},"source":["def linear_regression(dataset, label):\n","  return np.linalg.pinv(dataset) @ label"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BFYLi63dC6uI","colab_type":"text"},"source":["#### 2. Tìm tham số cho model M2.\n","- Sử dụng model hồi quy tuyến tính.\n","- Dataset chứa các review text trong tập training đã được chuyển thành dạng histogram vector.\n","- Label được chuyển thành dạng one-hot encoding."]},{"cell_type":"markdown","metadata":{"id":"IeV6PlTjDtuR","colab_type":"text"},"source":["> Chuẩn bị data và label cho việc training."]},{"cell_type":"code","metadata":{"id":"yHEHOGLyC55j","colab_type":"code","colab":{}},"source":["overall, review = read_data(train_set_path)\n","label_matrix = convert_label(overall)\n","vocab = make_vocab(review)\n","histogram_matrix = embedding(review, vocab)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GyxLwcvCHk8M","colab_type":"text"},"source":["> Huấn luyện model, tìm tham số model."]},{"cell_type":"code","metadata":{"id":"jfvUtI3uHsYN","colab_type":"code","colab":{}},"source":["param = linear_regression(histogram_matrix, label_matrix)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vx4WkQ93JOR7","colab_type":"text"},"source":["### V. Kiểm thử độ chính xác của model.\n","> Dùng hàm softmax để quyết định nhãn của text.  \n","Hàm softmax `scipy.special.softmax` sẽ trả ra một phân phối xác suất của text vào 5 lớp. Chọn lớp có xác suất cao nhất.  "]},{"cell_type":"markdown","metadata":{"id":"_z29kyMQLAx9","colab_type":"text"},"source":["#### 1. Cài đặt hàm softmax để trả về label của text trong valib.json\n","- Hàm `softmax` sẽ trả về phân phối xác suất của text vào 5 class.   \n","- Dùng `np.argmax` để trả về label của class có xác suất cao nhất. "]},{"cell_type":"code","metadata":{"id":"oFDq38dPJNq_","colab_type":"code","colab":{}},"source":["def softmax(x):\n","  return np.exp(x)/np.sum(np.exp(x))\n","\n","def define_label(x):\n","  distribution = softmax(x)\n","  return np.argmax(distribution) + 1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e8Awx4FDMWyy","colab_type":"text"},"source":["#### 2. Cài đặt hàm tính accuracy của model: lấy tổng số text phân lớp đúng/số text đem kiểm thử."]},{"cell_type":"code","metadata":{"id":"D2pi3En5MHDE","colab_type":"code","colab":{}},"source":["def accuracy(y_predict, overall):\n","  count = 0\n","  for i in range(len(y_predict)):\n","    label_predict = define_label(y_predict[i])\n","    if int(label_predict) == int(overall[i]):\n","      count += 1\n","  return count/len(overall)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y9ahiX9TNpat","colab_type":"text"},"source":["#### 3. Kiểm thử model trên tập valid.json\n","> Chuẩn bị dữ liệu.\n"]},{"cell_type":"code","metadata":{"id":"nWHrCrT4N3DU","colab_type":"code","colab":{}},"source":["overall_valid, review_valid = read_data(valid_set_path)\n","histogram_matrix_valid = embedding(review_valid, vocab)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8V-HhDntOiYK","colab_type":"text"},"source":["> Tính label dự đoán."]},{"cell_type":"code","metadata":{"id":"Qdz__e_tOhZ6","colab_type":"code","colab":{}},"source":["y_predict = np.dot(histogram_matrix_valid, param)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-RiC7d_dPCaU","colab_type":"text"},"source":["> Tính accuracy."]},{"cell_type":"code","metadata":{"id":"pscvDl9DOcuf","colab_type":"code","colab":{}},"source":["acc = accuracy(y_predict, overall_valid)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JCljY5SiPgSw","colab_type":"text"},"source":["## OUTPUT THU ĐƯỢC"]},{"cell_type":"code","metadata":{"id":"whNMQxysPNoR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1599663686167,"user_tz":-420,"elapsed":185120,"user":{"displayName":"Quang Tuấn Võ Trần","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTSWSVAF1KiDNCU5eVGF0F26JXJ1HjprJg9JdK=s64","userId":"11002199741059132758"}},"outputId":"b80b5d4e-de2a-47cd-e2af-436ac29682f0"},"source":["print(valid_text_processing(review_valid[int(random_number)], vocab))\n","print(f'M2 - {acc}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['brought', 'back', 'num', 'player', 'mode', 'like', 'mario', 'parti', 'num', '&', 'num']\n","M2 - 0.522\n"],"name":"stdout"}]}]}